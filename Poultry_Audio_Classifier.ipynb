{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - librosa\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _openmp_mutex-4.5          |            1_gnu          22 KB\n",
      "    appdirs-1.4.4              |     pyh9f0ad1d_0          13 KB  conda-forge\n",
      "    audioread-2.1.9            |   py37h89c1867_1          33 KB  conda-forge\n",
      "    conda-4.11.0               |   py37h89c1867_0        16.9 MB  conda-forge\n",
      "    ffmpeg-4.2.2               |       h20bf706_0        59.6 MB\n",
      "    gettext-0.19.8.1           |    h0b5b191_1005         3.6 MB  conda-forge\n",
      "    gnutls-3.6.13              |       h85f3911_1         2.0 MB  conda-forge\n",
      "    lame-3.100                 |    h7f98852_1001         496 KB  conda-forge\n",
      "    libflac-1.3.3              |       h9c3ff4c_1         486 KB  conda-forge\n",
      "    libgcc-ng-9.3.0            |      h5101ec6_17         4.8 MB\n",
      "    libgomp-9.3.0              |      h5101ec6_17         311 KB\n",
      "    libogg-1.3.4               |       h7f98852_1         206 KB  conda-forge\n",
      "    libopus-1.3.1              |       h7f98852_1         255 KB  conda-forge\n",
      "    librosa-0.8.1              |     pyhd8ed1ab_0         147 KB  conda-forge\n",
      "    libsndfile-1.0.31          |       h9c3ff4c_1         602 KB  conda-forge\n",
      "    libstdcxx-ng-11.2.0        |      he4da1e4_11         4.2 MB  conda-forge\n",
      "    libvorbis-1.3.7            |       h9c3ff4c_0         280 KB  conda-forge\n",
      "    libvpx-1.7.0               |       h439df22_0         1.2 MB\n",
      "    nettle-3.6                 |       he412f7d_0         6.5 MB  conda-forge\n",
      "    openh264-2.1.1             |       h780b84a_0         1.5 MB  conda-forge\n",
      "    pooch-1.5.2                |     pyhd8ed1ab_0          45 KB  conda-forge\n",
      "    pysoundfile-0.10.3.post1   |     pyhd3deb0d_0          23 KB  conda-forge\n",
      "    resampy-0.2.2              |             py_0         332 KB  conda-forge\n",
      "    x264-1!157.20191217        |       h7b6447c_0         922 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       104.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
      "  appdirs            conda-forge/noarch::appdirs-1.4.4-pyh9f0ad1d_0\n",
      "  audioread          conda-forge/linux-64::audioread-2.1.9-py37h89c1867_1\n",
      "  ffmpeg             pkgs/main/linux-64::ffmpeg-4.2.2-h20bf706_0\n",
      "  gettext            conda-forge/linux-64::gettext-0.19.8.1-h0b5b191_1005\n",
      "  gnutls             conda-forge/linux-64::gnutls-3.6.13-h85f3911_1\n",
      "  lame               conda-forge/linux-64::lame-3.100-h7f98852_1001\n",
      "  libflac            conda-forge/linux-64::libflac-1.3.3-h9c3ff4c_1\n",
      "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
      "  libogg             conda-forge/linux-64::libogg-1.3.4-h7f98852_1\n",
      "  libopus            conda-forge/linux-64::libopus-1.3.1-h7f98852_1\n",
      "  librosa            conda-forge/noarch::librosa-0.8.1-pyhd8ed1ab_0\n",
      "  libsndfile         conda-forge/linux-64::libsndfile-1.0.31-h9c3ff4c_1\n",
      "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-h9c3ff4c_0\n",
      "  libvpx             pkgs/main/linux-64::libvpx-1.7.0-h439df22_0\n",
      "  nettle             conda-forge/linux-64::nettle-3.6-he412f7d_0\n",
      "  openh264           conda-forge/linux-64::openh264-2.1.1-h780b84a_0\n",
      "  pooch              conda-forge/noarch::pooch-1.5.2-pyhd8ed1ab_0\n",
      "  pysoundfile        conda-forge/noarch::pysoundfile-0.10.3.post1-pyhd3deb0d_0\n",
      "  resampy            conda-forge/noarch::resampy-0.2.2-py_0\n",
      "  x264               pkgs/main/linux-64::x264-1!157.20191217-h7b6447c_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               4.10.3-py37h89c1867_3 --> 4.11.0-py37h89c1867_0\n",
      "  libgcc-ng                                9.1.0-hdf63c60_0 --> 9.3.0-h5101ec6_17\n",
      "  libstdcxx-ng       pkgs/main::libstdcxx-ng-9.1.0-hdf63c6~ --> conda-forge::libstdcxx-ng-11.2.0-he4da1e4_11\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pooch-1.5.2          | 45 KB     | ##################################### | 100% \n",
      "libogg-1.3.4         | 206 KB    | ##################################### | 100% \n",
      "pysoundfile-0.10.3.p | 23 KB     | ##################################### | 100% \n",
      "libstdcxx-ng-11.2.0  | 4.2 MB    | ##################################### | 100% \n",
      "openh264-2.1.1       | 1.5 MB    | ##################################### | 100% \n",
      "ffmpeg-4.2.2         | 59.6 MB   | ##################################### | 100% \n",
      "appdirs-1.4.4        | 13 KB     | ##################################### | 100% \n",
      "gettext-0.19.8.1     | 3.6 MB    | ##################################### | 100% \n",
      "libsndfile-1.0.31    | 602 KB    | ##################################### | 100% \n",
      "lame-3.100           | 496 KB    | ##################################### | 100% \n",
      "libvpx-1.7.0         | 1.2 MB    | ##################################### | 100% \n",
      "_openmp_mutex-4.5    | 22 KB     | ##################################### | 100% \n",
      "libgomp-9.3.0        | 311 KB    | ##################################### | 100% \n",
      "conda-4.11.0         | 16.9 MB   | ##################################### | 100% \n",
      "libflac-1.3.3        | 486 KB    | ##################################### | 100% \n",
      "librosa-0.8.1        | 147 KB    | ##################################### | 100% \n",
      "x264-1!157.20191217  | 922 KB    | ##################################### | 100% \n",
      "resampy-0.2.2        | 332 KB    | ##################################### | 100% \n",
      "libopus-1.3.1        | 255 KB    | ##################################### | 100% \n",
      "libvorbis-1.3.7      | 280 KB    | ##################################### | 100% \n",
      "nettle-3.6           | 6.5 MB    | ##################################### | 100% \n",
      "gnutls-3.6.13        | 2.0 MB    | ##################################### | 100% \n",
      "libgcc-ng-9.3.0      | 4.8 MB    | ##################################### | 100% \n",
      "audioread-2.1.9      | 33 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Audio modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_features import AudioFeatures, calc_log_mel_energy_features\n",
    "from audio_signal import AudioSignal\n",
    "from audio_labels import load_labels, clean_overlapping_labels\n",
    "from noise_reducer import NoiseReducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import general libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import tempfile\n",
    "\n",
    "from time import gmtime, strftime \n",
    "from datetime import datetime\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "import boto3\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Pandas version and update pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "Warning: 2 possible package resolutions (only showing differing packages):\n",
      "  - defaults/linux-64::six-1.15.0-py37h06a4308_0, defaults/linux-64::tenacity-8.0.1-py37h06a4308_0, defaults/noarch::plotly-5.1.0-pyhd3eb1b0_0\n",
      "  - defaults/linux-64::plotly-3.6.1-py37_0, defaults/linux-64::retrying-1.3.3-py37_2, defaults/noarch::six-1.16.0-pyhd3eb1b0done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    appdirs-1.4.4              |     pyhd3eb1b0_0          12 KB\n",
      "    autovizwidget-0.18.0       |     pyhd3eb1b0_0          14 KB\n",
      "    ca-certificates-2021.10.26 |       h06a4308_2         115 KB\n",
      "    certifi-2021.10.8          |   py37h06a4308_0         151 KB\n",
      "    cryptography-35.0.0        |   py37hd23ed53_0         1.3 MB\n",
      "    gnutls-3.6.15              |       he1e5248_0         1.0 MB\n",
      "    hdijupyterutils-0.19.0     |     pyhd3eb1b0_0          10 KB\n",
      "    idna-3.3                   |     pyhd3eb1b0_0          49 KB\n",
      "    lame-3.100                 |       h7b6447c_0         323 KB\n",
      "    ld_impl_linux-64-2.35.1    |       h7274673_9         586 KB\n",
      "    libedit-3.1.20210910       |       h7f8727e_0         166 KB\n",
      "    libffi-3.3                 |       he6710b0_2          50 KB\n",
      "    libidn2-2.3.2              |       h7f8727e_0          81 KB\n",
      "    libntlm-1.6                |       h7f8727e_0          32 KB\n",
      "    libogg-1.3.5               |       h27cfd23_1         199 KB\n",
      "    libopus-1.3.1              |       h7b6447c_0         491 KB\n",
      "    libstdcxx-ng-9.3.0         |      hd4cf53a_17         3.1 MB\n",
      "    libtasn1-4.16.0            |       h27cfd23_0          58 KB\n",
      "    libunistring-0.9.10        |       h27cfd23_0         536 KB\n",
      "    libvorbis-1.3.7            |       h7b6447c_0         398 KB\n",
      "    ncurses-6.3                |       h7f8727e_2         782 KB\n",
      "    nettle-3.7.3               |       hbbd107a_1         809 KB\n",
      "    openh264-2.1.0             |       hd408876_0         722 KB\n",
      "    pip-21.2.2                 |   py37h06a4308_0         1.8 MB\n",
      "    plotly-5.1.0               |     pyhd3eb1b0_0         2.7 MB\n",
      "    pooch-1.4.0                |     pyhd3eb1b0_0          41 KB\n",
      "    pure-sasl-0.6.2            |             py_0          14 KB\n",
      "    pycosat-0.6.3              |   py37h27cfd23_0          81 KB\n",
      "    pycparser-2.21             |     pyhd3eb1b0_0          94 KB\n",
      "    pykerberos-1.2.1           |   py37ha6b2b2b_1         214 KB\n",
      "    pyopenssl-21.0.0           |     pyhd3eb1b0_1          49 KB\n",
      "    pysocks-1.7.1              |           py37_1          27 KB\n",
      "    readline-8.1               |       h27cfd23_0         362 KB\n",
      "    requests-2.26.0            |     pyhd3eb1b0_0          59 KB\n",
      "    requests-kerberos-0.12.0   |   py37h06a4308_0         254 KB\n",
      "    setuptools-58.0.4          |   py37h06a4308_0         775 KB\n",
      "    six-1.15.0                 |   py37h06a4308_0          27 KB\n",
      "    tenacity-8.0.1             |   py37h06a4308_0          38 KB\n",
      "    thrift-0.13.0              |   py37h2531618_0         117 KB\n",
      "    tk-8.6.11                  |       h1ccaba5_0         3.0 MB\n",
      "    tqdm-4.62.3                |     pyhd3eb1b0_1          83 KB\n",
      "    urllib3-1.26.7             |     pyhd3eb1b0_0         111 KB\n",
      "    wheel-0.37.0               |     pyhd3eb1b0_1          33 KB\n",
      "    xz-5.2.5                   |       h7b6447c_0         341 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        21.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0\n",
      "  libtasn1           pkgs/main/linux-64::libtasn1-4.16.0-h27cfd23_0\n",
      "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2021.10.~ --> pkgs/main::ca-certificates-2021.10.26-h06a4308_2\n",
      "  cryptography                           2.8-py37h1ba5d50_0 --> 35.0.0-py37hd23ed53_0\n",
      "  gnutls              conda-forge::gnutls-3.6.13-h85f3911_1 --> pkgs/main::gnutls-3.6.15-he1e5248_0\n",
      "  idna                  pkgs/main/linux-64::idna-2.8-py37_0 --> pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
      "  ld_impl_linux-64                        2.33.1-h53a641e_7 --> 2.35.1-h7274673_9\n",
      "  libedit                           3.1.20181209-hc058e9b_0 --> 3.1.20210910-h7f8727e_0\n",
      "  libntlm            conda-forge::libntlm-1.4-h516909a_1002 --> pkgs/main::libntlm-1.6-h7f8727e_0\n",
      "  libogg               conda-forge::libogg-1.3.4-h7f98852_1 --> pkgs/main::libogg-1.3.5-h27cfd23_1\n",
      "  ncurses                                    6.2-he6710b0_0 --> 6.3-h7f8727e_2\n",
      "  nettle                 conda-forge::nettle-3.6-he412f7d_0 --> pkgs/main::nettle-3.7.3-hbbd107a_1\n",
      "  pip                                         20.0.2-py37_1 --> 21.2.2-py37h06a4308_0\n",
      "  pycparser          pkgs/main/linux-64::pycparser-2.19-py~ --> pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
      "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-~ --> pkgs/main/noarch::pyopenssl-21.0.0-pyhd3eb1b0_1\n",
      "  pysocks                                      1.7.1-py37_0 --> 1.7.1-py37_1\n",
      "  readline             conda-forge::readline-8.0-he28a2e2_2 --> pkgs/main::readline-8.1-h27cfd23_0\n",
      "  requests           pkgs/main/linux-64::requests-2.22.0-p~ --> pkgs/main/noarch::requests-2.26.0-pyhd3eb1b0_0\n",
      "  setuptools                                  45.2.0-py37_0 --> 58.0.4-py37h06a4308_0\n",
      "  six                                         1.14.0-py37_0 --> 1.15.0-py37h06a4308_0\n",
      "  tqdm                                          4.42.1-py_0 --> 4.62.3-pyhd3eb1b0_1\n",
      "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py~ --> pkgs/main/noarch::urllib3-1.26.7-pyhd3eb1b0_0\n",
      "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37~ --> pkgs/main/noarch::wheel-0.37.0-pyhd3eb1b0_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  appdirs            conda-forge::appdirs-1.4.4-pyh9f0ad1d~ --> pkgs/main::appdirs-1.4.4-pyhd3eb1b0_0\n",
      "  autovizwidget      conda-forge::autovizwidget-0.19.1-pyh~ --> pkgs/main::autovizwidget-0.18.0-pyhd3eb1b0_0\n",
      "  certifi            conda-forge::certifi-2021.10.8-py37h8~ --> pkgs/main::certifi-2021.10.8-py37h06a4308_0\n",
      "  hdijupyterutils    conda-forge::hdijupyterutils-0.19.1-p~ --> pkgs/main::hdijupyterutils-0.19.0-pyhd3eb1b0_0\n",
      "  lame                conda-forge::lame-3.100-h7f98852_1001 --> pkgs/main::lame-3.100-h7b6447c_0\n",
      "  libffi                 conda-forge::libffi-3.3-h58526e2_2 --> pkgs/main::libffi-3.3-he6710b0_2\n",
      "  libopus             conda-forge::libopus-1.3.1-h7f98852_1 --> pkgs/main::libopus-1.3.1-h7b6447c_0\n",
      "  libstdcxx-ng       conda-forge::libstdcxx-ng-11.2.0-he4d~ --> pkgs/main::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
      "  libvorbis          conda-forge::libvorbis-1.3.7-h9c3ff4c~ --> pkgs/main::libvorbis-1.3.7-h7b6447c_0\n",
      "  openh264           conda-forge::openh264-2.1.1-h780b84a_0 --> pkgs/main::openh264-2.1.0-hd408876_0\n",
      "  plotly             conda-forge::plotly-5.3.1-pyhd8ed1ab_0 --> pkgs/main::plotly-5.1.0-pyhd3eb1b0_0\n",
      "  pooch               conda-forge::pooch-1.5.2-pyhd8ed1ab_0 --> pkgs/main::pooch-1.4.0-pyhd3eb1b0_0\n",
      "  pure-sasl          conda-forge::pure-sasl-0.6.2-pyhd8ed1~ --> pkgs/main::pure-sasl-0.6.2-py_0\n",
      "  pykerberos         conda-forge::pykerberos-1.2.1-py37h74~ --> pkgs/main::pykerberos-1.2.1-py37ha6b2b2b_1\n",
      "  requests-kerberos  conda-forge::requests-kerberos-0.12.0~ --> pkgs/main::requests-kerberos-0.12.0-py37h06a4308_0\n",
      "  tenacity           conda-forge/noarch::tenacity-8.0.1-py~ --> pkgs/main/linux-64::tenacity-8.0.1-py37h06a4308_0\n",
      "  thrift             conda-forge::thrift-0.13.0-py37h74590~ --> pkgs/main::thrift-0.13.0-py37h2531618_0\n",
      "  tk                      conda-forge::tk-8.6.11-h21135ba_0 --> pkgs/main::tk-8.6.11-h1ccaba5_0\n",
      "  xz                       conda-forge::xz-5.2.5-h516909a_1 --> pkgs/main::xz-5.2.5-h7b6447c_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pycosat                              0.6.3-py37h7b6447c_0 --> 0.6.3-py37h27cfd23_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "hdijupyterutils-0.19 | 10 KB     | ##################################### | 100% \n",
      "libunistring-0.9.10  | 536 KB    | ##################################### | 100% \n",
      "libogg-1.3.5         | 199 KB    | ##################################### | 100% \n",
      "pycosat-0.6.3        | 81 KB     | ##################################### | 100% \n",
      "plotly-5.1.0         | 2.7 MB    | ##################################### | 100% \n",
      "libntlm-1.6          | 32 KB     | ##################################### | 100% \n",
      "wheel-0.37.0         | 33 KB     | ##################################### | 100% \n",
      "libtasn1-4.16.0      | 58 KB     | ##################################### | 100% \n",
      "urllib3-1.26.7       | 111 KB    | ##################################### | 100% \n",
      "cryptography-35.0.0  | 1.3 MB    | ##################################### | 100% \n",
      "libidn2-2.3.2        | 81 KB     | ##################################### | 100% \n",
      "libopus-1.3.1        | 491 KB    | ##################################### | 100% \n",
      "nettle-3.7.3         | 809 KB    | ##################################### | 100% \n",
      "ncurses-6.3          | 782 KB    | ##################################### | 100% \n",
      "libstdcxx-ng-9.3.0   | 3.1 MB    | ##################################### | 100% \n",
      "gnutls-3.6.15        | 1.0 MB    | ##################################### | 100% \n",
      "pycparser-2.21       | 94 KB     | ##################################### | 100% \n",
      "libedit-3.1.20210910 | 166 KB    | ##################################### | 100% \n",
      "pyopenssl-21.0.0     | 49 KB     | ##################################### | 100% \n",
      "openh264-2.1.0       | 722 KB    | ##################################### | 100% \n",
      "six-1.15.0           | 27 KB     | ##################################### | 100% \n",
      "autovizwidget-0.18.0 | 14 KB     | ##################################### | 100% \n",
      "xz-5.2.5             | 341 KB    | ##################################### | 100% \n",
      "appdirs-1.4.4        | 12 KB     | ##################################### | 100% \n",
      "requests-kerberos-0. | 254 KB    | ##################################### | 100% \n",
      "lame-3.100           | 323 KB    | ##################################### | 100% \n",
      "thrift-0.13.0        | 117 KB    | ##################################### | 100% \n",
      "idna-3.3             | 49 KB     | ##################################### | 100% \n",
      "pip-21.2.2           | 1.8 MB    | ##################################### | 100% \n",
      "ca-certificates-2021 | 115 KB    | ##################################### | 100% \n",
      "libvorbis-1.3.7      | 398 KB    | ##################################### | 100% \n",
      "pooch-1.4.0          | 41 KB     | ##################################### | 100% \n",
      "ld_impl_linux-64-2.3 | 586 KB    | ##################################### | 100% \n",
      "tk-8.6.11            | 3.0 MB    | ##################################### | 100% \n",
      "libffi-3.3           | 50 KB     | ##################################### | 100% \n",
      "tenacity-8.0.1       | 38 KB     | ##################################### | 100% \n",
      "requests-2.26.0      | 59 KB     | ##################################### | 100% \n",
      "readline-8.1         | 362 KB    | ##################################### | 100% \n",
      "pure-sasl-0.6.2      | 14 KB     | ##################################### | 100% \n",
      "pykerberos-1.2.1     | 214 KB    | ##################################### | 100% \n",
      "setuptools-58.0.4    | 775 KB    | ##################################### | 100% \n",
      "certifi-2021.10.8    | 151 KB    | ##################################### | 100% \n",
      "pysocks-1.7.1        | 27 KB     | ##################################### | 100% \n",
      "tqdm-4.62.3          | 83 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda update pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get file keys from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_keys(bucket, prefix, client=None):\n",
    "    if client is None:\n",
    "        client = boto3.client('s3')\n",
    "    objs = client.list_objects(Bucket = bucket ,Prefix = prefix)\n",
    "    keys = []\n",
    "    for x in objs['Contents']:\n",
    "        keys.append(x['Key'])\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create client and get key lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "client = boto3.client('s3')\n",
    "\n",
    "audio_keys = get_file_keys('demo-bucket', 'Training_Data/Original_Audio/', client)[1:]\n",
    "label_keys = get_file_keys('demo-bucket', 'Training_Data/Labels/', client)[1:]\n",
    "\n",
    "print(len(audio_keys))\n",
    "print(len(label_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get audio file information from file key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file_key_info(key):\n",
    "    file_name = key.split('/')[-1]\n",
    "    splits = file_name.split('_')\n",
    "    y, m, d = splits[2].split('-')\n",
    "    h, mn, s, _ = splits[3].split('.')\n",
    "    \n",
    "    info = {'year': int(y), 'month': int(m), 'day': int(d), 'hour': int(h), 'minute': int(mn), 'second':int(s)}\n",
    "    \n",
    "    return info\n",
    "\n",
    "#print(parse_file_key_info(audio_keys[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate age and day/night variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_age_DN(key, nrow, start_date=datetime(2021,5,11)):\n",
    "    info = parse_file_key_info(key)\n",
    "    if info['hour'] < 8 or info['hour'] >= 22:\n",
    "        dn = np.full((nrow,1), 0) #0 means Nighttime hours, before 8am or after 10pm\n",
    "    else:\n",
    "        dn = np.full((nrow,1), 1) #1 means Daytime hours, after 8am or before 10pm\n",
    "\n",
    "    #calculates age of birds in total seconds (rounded to nearest day)\n",
    "    age = np.full((nrow,1), (datetime(info['year'],info['month'],info['day']) - start_date).total_seconds()) #create age array\n",
    "    \n",
    "    return age, dn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare audio labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['cluck', 'trill', 'squawk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to load an audio feature from S3, optional arguments to run noise reduction algorithm and calculate deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_features(bucket, tempfile, file_key, deltas=False, noise_reducer=False):\n",
    "    audio_obj = bucket.Object(file_key)\n",
    "    with open(tempfile.name, 'wb') as f:\n",
    "        audio_obj.download_fileobj(f)\n",
    "        signal = AudioSignal.from_file(tempfile.name)\n",
    "        if noise_reducer:\n",
    "            signal = NoiseReducer.reduce_noise(signal)\n",
    "        features = calc_log_mel_energy_features(signal)\n",
    "        if deltas:\n",
    "            deltas = features.deltas()\n",
    "            deltas2 = deltas.deltas()\n",
    "            features = AudioFeatures.stack(features, deltas, deltas2)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate numpy data arrays from list of audio and label file keys. Boolean arguments to add deltas, run through noise reduction algo, and calculate age/day and night variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_from_keys(bucket_name, audio_keys, label_keys, label_list=None, deltas=False, noise_reducer=False, calc_age_dn=False):\n",
    "    s3 = boto3.resource('s3', region_name='us-east-1')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    feature_files = []\n",
    "    day_night = []\n",
    "    ages = []\n",
    "    tmp = tempfile.NamedTemporaryFile()\n",
    "    \n",
    "    label_keys.sort()\n",
    "    audio_keys.sort()\n",
    "    audio_names = [''.join(fname.split('/')[-1].split('_')) for fname in audio_keys] #NEED TO CHANGE TO .split('_')[:-1] IF NOT USING DENOISED\n",
    "    label_names = [''.join(fname.split('/')[-1].split('_')[:-1])+'.flac' for fname in label_keys]\n",
    "\n",
    "    assert audio_names == label_names, 'Files do not match' #check if audio files match label files\n",
    "\n",
    "    for ak, lk in zip(audio_keys, label_keys):\n",
    "        try:\n",
    "            features = load_audio_features(bucket, tmp, ak, deltas=deltas, noise_reducer=noise_reducer)\n",
    "            labels = load_labels(bucket.Object(lk).get()['Body'])                \n",
    "        except RuntimeError:\n",
    "            print(ak.split('/')[-1])\n",
    "            continue\n",
    "        \n",
    "        if calc_age_dn:\n",
    "            nrow = features.features.shape[0]\n",
    "            age, dn = calc_age_DN(ak, nrow)\n",
    "            day_night.append(dn)\n",
    "            ages.append(age)\n",
    "                           \n",
    "        features.event_names = label_list\n",
    "        features.match_labels(labels)\n",
    "        feature_files.append(features)\n",
    "\n",
    "    combined_features = AudioFeatures.concatenate(*feature_files)\n",
    "    \n",
    "    if calc_age_dn:                       \n",
    "        age_vector = np.vstack(ages)\n",
    "        dn_vector = np.vstack(day_night)\n",
    "        x = np.hstack((age_vector, dn_vector, combined_features.features))\n",
    "    else: \n",
    "        x = combined_features.features\n",
    "                           \n",
    "    combined_labels = combined_features.true_events\n",
    "    for i in range(combined_labels.shape[1]):\n",
    "        combined_labels[combined_labels[:,i] > 0, i] = i+1\n",
    "\n",
    "    y = np.max(combined_labels, axis = -1)\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "bucket_name = 'demo-bucket'\n",
    "x, y = dataset_from_keys(bucket_name, audio_keys, label_keys, label_list, deltas=True, noise_reducer=True, calc_age_dn=True)\n",
    "print(x.shape)\n",
    "print(x[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train/validate/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1765, random_state=1) # 0.1765 x 0.85 = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to export data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "#ouputs data matrix as csv. Y is the first column in the csv file.\n",
    "def write_data_to_s3(x, y, bucket_name, filename, prefix='Demo/Demo_Model_Data'):\n",
    "    csv_buffer = StringIO()\n",
    "    mat = np.hstack((y.reshape(y.shape[0],1), x))\n",
    "    np.savetxt(csv_buffer, mat, delimiter=',')\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object(bucket_name, prefix+'/'+filename).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_to_s3(x_train, y_train, bucket_name, 'train.csv')\n",
    "write_data_to_s3(x_val, y_val, bucket_name, 'validate.csv')\n",
    "write_data_to_s3(x_test, y_test, bucket_name, 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to upsample minority classes to the same size as the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x, y, seed=47):\n",
    "    np.random.seed(seed)\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    majority_count = np.max(counts)\n",
    "    majority_class = classes[np.argmax(counts)]\n",
    "    \n",
    "    resamps = [x]\n",
    "    ys = [y[:,None]]\n",
    "    for clss, cnt in zip(classes, counts):\n",
    "        if clss != majority_class:\n",
    "            sub_x = x[np.where(y==clss)]\n",
    "            sample = sub_x[np.random.choice(np.arange(cnt), size=majority_count-cnt, replace=True)]\n",
    "            resamps.append(sample)\n",
    "            ys.append(np.full(shape=(majority_count-cnt,1), fill_value=clss))                               \n",
    "                                            \n",
    "    return (np.vstack(resamps), np.vstack(ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set with balanced classes and write to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_x_train, upsampled_y_train = upsample(x_train, y_train)\n",
    "write_data_to_s3(upsampled_x_train, upsampled_y_train, bucket_name, 'upsampled_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to use with hyperparameter tuning or to fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://demo-bucket/Howell_Models/Demo_Model',\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(objective = 'multi:softmax',\n",
    "                        num_class=(len(label_list)+1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in S3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=\"s3://demo-bucket/Howell_Models/Data/Demo_Model_Data/train.csv\", content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=\"s3://demo-bucket/Howell_Models/Data/Demo_Model_Data/validate.csv\", content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model. Uncomment to fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Hyperparameter Tuning. Uncomment to tune model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#from https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd\n",
    "# Define exploration boundaries (default suggested values from Amazon SageMaker Documentation)\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 1000, scaling_type=\"Auto\"),\n",
    "    'colsample_bylevel': ContinuousParameter(0.1, 1,scaling_type=\"Logarithmic\"),\n",
    "    'colsample_bytree': ContinuousParameter(0.5, 1, scaling_type='Logarithmic'),\n",
    "    'eta': ContinuousParameter(0.1, 0.5, scaling_type='Logarithmic'),\n",
    "    'gamma':ContinuousParameter(0, 5, scaling_type='Auto'),\n",
    "    'lambda': ContinuousParameter(0,100,scaling_type='Auto'),\n",
    "    'max_delta_step': IntegerParameter(0,10,scaling_type='Auto'),\n",
    "    'max_depth': IntegerParameter(0,10,scaling_type='Auto'),\n",
    "    'min_child_weight': ContinuousParameter(0,10,scaling_type='Auto'),\n",
    "    'num_round': IntegerParameter(1,4000,scaling_type='Auto'),\n",
    "    'subsample': ContinuousParameter(0.5,1,scaling_type='Logarithmic')}\n",
    "\n",
    "objective_metric_name = 'validation:mlogloss'\n",
    "\n",
    "tuner_log = HyperparameterTuner(\n",
    "    xgb,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=3,\n",
    "    strategy='Bayesian',\n",
    "    objective_type = 'Minimize'\n",
    ")\n",
    "\n",
    "## Starts the hyperparameter tuning job\n",
    "tuner_log.fit({'train': s3_input_train, 'validation': s3_input_validation}, include_cls_metadata=False)\n",
    "\n",
    "## Prints the status of the latest hyperparameter tuning job\n",
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment to deploy best model once tuning job is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.serializers import CSVSerializer\n",
    "#xgb_predictor = tuner_log.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', serializer=CSVSerializer())\n",
    "#xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained model. Uncomment to load pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in pre-trained model\n"
     ]
    }
   ],
   "source": [
    "#sess = sagemaker.Session()\n",
    "# Read in the pre-trained model\n",
    "print(\"Reading in pre-trained model\")\n",
    "model_data = 's3://demo-bucket/final_trained_model/model.tar.gz'\n",
    "from sagemaker.predictor import Predictor\n",
    "    \n",
    "xgb = sagemaker.model.Model(image_uri=container, \n",
    "                            model_data=model_data, \n",
    "                            role=role,\n",
    "                            predictor_cls=Predictor,\n",
    "                            sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy prediction endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "xgb_predictor=xgb.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    serializer=CSVSerializer())\n",
    "\n",
    "name = xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete endpoint. RUN CELL ONCE INFERENCE IS COMPLETED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-test-model.html\n",
    "def predict(data, predictor, rows=1000):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict labels on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=predict(x_test, xgb_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display confusion matrix and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix of the model is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53095</td>\n",
       "      <td>703</td>\n",
       "      <td>37</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>271</td>\n",
       "      <td>251</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1   2   3\n",
       "0  53095  703  37  91\n",
       "1    271  251   4  15\n",
       "2     43    3  21   9\n",
       "3     61   33   7  79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     No Call      0.993     0.985     0.989     53926\n",
      "       Cluck      0.254     0.464     0.328       541\n",
      "       Trill      0.304     0.276     0.290        76\n",
      "      Squawk      0.407     0.439     0.422       180\n",
      "\n",
      "    accuracy                          0.977     54723\n",
      "   macro avg      0.490     0.541     0.507     54723\n",
      "weighted avg      0.983     0.977     0.979     54723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_=confusion_matrix(y_test,preds)\n",
    "print(\"The confusion matrix of the model is:\")\n",
    "conf_mat = pd.DataFrame(confusion_matrix_)\n",
    "display(conf_mat)\n",
    "\n",
    "report = classification_report(y_test, preds, labels = [0., 1., 2., 3.], target_names=['No Call', 'Cluck', 'Trill', 'Squawk'], digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, filename, prefix = 'Demo/Demo_metrics'):\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer)\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object('demo-bucket', prefix+'/'+filename).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "save_dataframe(conf_mat, 'confusion_matrix.csv')\n",
    "#save_dataframe(report, 'report_dataframe.csv')\n",
    "save_dataframe(pd.DataFrame(np.hstack((preds[:,None], y_test[:,None]))), 'y_pred_y_true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sounds(y):\n",
    "    zero = np.count_nonzero(y==0)\n",
    "    one = np.count_nonzero(y==1)\n",
    "    two = np.count_nonzero(y==2)\n",
    "    three = np.count_nonzero(y==3)\n",
    "    \n",
    "    assert zero+one+two+three == y.shape[0]\n",
    "    \n",
    "    return np.array([zero, one, two, three])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict sounds from another bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from io import StringIO\n",
    "bucket_name='demo-bucket'\n",
    "tmp = tempfile.NamedTemporaryFile()\n",
    "\n",
    "days_list=[\"2021-08-\"+str(i).zfill(2)+\"/\" for i in list(range(24,32))]\\\n",
    "+[\"2021-09-\"+str(i).zfill(2)+\"/\" for i in list(range(1,18))]\n",
    "\n",
    "def predict_sounds(bucket_name, days_list, hours_list, label_list, start_date, deltas=True, noise_reducer=True, calc_age_dn=True):\n",
    "    s3 = boto3.resource('s3', region_name='us-east-1')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    tic = time.time()\n",
    "    client = boto3.client('s3')\n",
    "    for day in days_list:\n",
    "        class_by_file = []\n",
    "        day_name=day.split(\"/\")[-2]\n",
    "        print(\"day \",day_name,\"\\n\")\n",
    "        for hour in hours_list:\n",
    "            features_by_file = []\n",
    "            hour_name=hour.split(\"/\")[0]\n",
    "            print(\"hour \",hour_name,\"\\n\")\n",
    "            S3_location=day+hour\n",
    "            keys = get_file_keys(bucket_name, S3_location, client)[1:]\n",
    "            info = parse_file_key_info(keys[1])\n",
    "            for key in keys:\n",
    "                try:\n",
    "                    features = load_audio_features(bucket, tmp, key, deltas=deltas, noise_reducer=noise_reducer)\n",
    "                    x = features.features\n",
    "                    nrow = x.shape[0]\n",
    "                    if calc_age_dn:\n",
    "                        age, dn = calc_age_DN(key, nrow, start_date=start_date)\n",
    "                        x = np.hstack((age, dn, x))\n",
    "                    if nrow>2400:\n",
    "                        x=x[0:2400]\n",
    "                    features_by_file.append(x)\n",
    "                except RuntimeError:\n",
    "                    print(\"@\", end=\"\")\n",
    "                    continue\n",
    "            x_pred = np.vstack(features_by_file)\n",
    "            y_pred = predict(x_pred, xgb_predictor)\n",
    "            counts = count_sounds(y_pred)\n",
    "            date = [datetime(info['year'],info['month'],info['day'], info['hour'])]\n",
    "            class_by_file.append(np.hstack((date, counts)))\n",
    "            toc = time.time()\n",
    "            print('Elapsed time is %f seconds \\n' % float(toc - tic))\n",
    "        pred_labels_df = pd.DataFrame(np.vstack(class_by_file), columns = ['date', 'no_sound']+label_list)\n",
    "        save_dataframe(pred_labels_df, f'{day_name}_labels.csv', 'Demo/Predicted_Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day  2021-08-24 \n",
      "\n",
      "hour  00 \n",
      "\n",
      "Elapsed time is 134.768576 seconds \n",
      "\n",
      "hour  01 \n",
      "\n",
      "@Elapsed time is 269.752064 seconds \n",
      "\n",
      "hour  02 \n",
      "\n",
      "@Elapsed time is 400.064224 seconds \n",
      "\n",
      "hour  03 \n",
      "\n",
      "Elapsed time is 528.698914 seconds \n",
      "\n",
      "hour  04 \n",
      "\n",
      "Elapsed time is 655.766397 seconds \n",
      "\n",
      "hour  05 \n",
      "\n",
      "@@@@@@Elapsed time is 770.634146 seconds \n",
      "\n",
      "hour  06 \n",
      "\n",
      "Elapsed time is 900.429334 seconds \n",
      "\n",
      "hour  07 \n",
      "\n",
      "@Elapsed time is 1029.437265 seconds \n",
      "\n",
      "hour  08 \n",
      "\n",
      "@Elapsed time is 1159.065686 seconds \n",
      "\n",
      "hour  09 \n",
      "\n",
      "Elapsed time is 1291.503906 seconds \n",
      "\n",
      "hour  10 \n",
      "\n",
      "Elapsed time is 1423.128326 seconds \n",
      "\n",
      "hour  11 \n",
      "\n",
      "Elapsed time is 1555.938940 seconds \n",
      "\n",
      "hour  12 \n",
      "\n",
      "@Elapsed time is 1685.190258 seconds \n",
      "\n",
      "hour  13 \n",
      "\n",
      "Elapsed time is 1814.570829 seconds \n",
      "\n",
      "hour  14 \n",
      "\n",
      "@@@Elapsed time is 1938.424582 seconds \n",
      "\n",
      "hour  15 \n",
      "\n",
      "@@@Elapsed time is 2062.678583 seconds \n",
      "\n",
      "hour  16 \n",
      "\n",
      "@@Elapsed time is 2191.086858 seconds \n",
      "\n",
      "hour  17 \n",
      "\n",
      "@@Elapsed time is 2320.910332 seconds \n",
      "\n",
      "hour  18 \n",
      "\n",
      "@@@Elapsed time is 2449.836339 seconds \n",
      "\n",
      "hour  19 \n",
      "\n",
      "Elapsed time is 2587.080605 seconds \n",
      "\n",
      "hour  20 \n",
      "\n",
      "@@@@@Elapsed time is 2717.104768 seconds \n",
      "\n",
      "hour  21 \n",
      "\n",
      "@@@@Elapsed time is 2846.739242 seconds \n",
      "\n",
      "hour  22 \n",
      "\n",
      "@Elapsed time is 2979.510152 seconds \n",
      "\n",
      "hour  23 \n",
      "\n",
      "Elapsed time is 3112.123542 seconds \n",
      "\n",
      "day  2021-08-25 \n",
      "\n",
      "hour  00 \n",
      "\n",
      "Elapsed time is 3249.993341 seconds \n",
      "\n",
      "hour  01 \n",
      "\n",
      "@Elapsed time is 3382.676281 seconds \n",
      "\n",
      "hour  02 \n",
      "\n",
      "@Elapsed time is 3513.027002 seconds \n",
      "\n",
      "hour  03 \n",
      "\n",
      "Elapsed time is 3645.116024 seconds \n",
      "\n",
      "hour  04 \n",
      "\n",
      "Elapsed time is 3775.022491 seconds \n",
      "\n",
      "hour  05 \n",
      "\n",
      "Elapsed time is 3905.114710 seconds \n",
      "\n",
      "hour  06 \n",
      "\n",
      "Elapsed time is 4036.668355 seconds \n",
      "\n",
      "hour  07 \n",
      "\n",
      "Elapsed time is 4168.845580 seconds \n",
      "\n",
      "hour  08 \n",
      "\n",
      "Elapsed time is 4299.597627 seconds \n",
      "\n",
      "hour  09 \n",
      "\n",
      "Elapsed time is 4432.113902 seconds \n",
      "\n",
      "hour  10 \n",
      "\n",
      "Elapsed time is 4565.504421 seconds \n",
      "\n",
      "hour  11 \n",
      "\n",
      "@@Elapsed time is 4695.155526 seconds \n",
      "\n",
      "hour  12 \n",
      "\n",
      "Elapsed time is 4832.075975 seconds \n",
      "\n",
      "hour  13 \n",
      "\n",
      "@@Elapsed time is 11625.597122 seconds \n",
      "\n",
      "hour  05 \n",
      "\n",
      "@@Elapsed time is 11725.116190 seconds \n",
      "\n",
      "hour  06 \n",
      "\n",
      "@Elapsed time is 11824.798820 seconds \n",
      "\n",
      "hour  07 \n",
      "\n",
      "Elapsed time is 11928.378377 seconds \n",
      "\n",
      "hour  08 \n",
      "\n",
      "Elapsed time is 12029.931106 seconds \n",
      "\n",
      "hour  09 \n",
      "\n",
      "@Elapsed time is 12132.172219 seconds \n",
      "\n",
      "hour  10 \n",
      "\n",
      "Elapsed time is 12236.355404 seconds \n",
      "\n",
      "hour  11 \n",
      "\n",
      "Elapsed time is 12342.448474 seconds \n",
      "\n",
      "hour  12 \n",
      "\n",
      "@Elapsed time is 12446.274386 seconds \n",
      "\n",
      "hour  13 \n",
      "\n",
      "@@@Elapsed time is 12546.771605 seconds \n",
      "\n",
      "hour  14 \n",
      "\n",
      "@Elapsed time is 12649.617591 seconds \n",
      "\n",
      "hour  15 \n",
      "\n",
      "Elapsed time is 12753.965261 seconds \n",
      "\n",
      "hour  16 \n",
      "\n",
      "Elapsed time is 12857.985922 seconds \n",
      "\n",
      "hour  17 \n",
      "\n",
      "Elapsed time is 12962.431202 seconds \n",
      "\n",
      "hour  18 \n",
      "\n",
      "Elapsed time is 13065.586451 seconds \n",
      "\n",
      "hour  19 \n",
      "\n",
      "Elapsed time is 13170.341208 seconds \n",
      "\n",
      "hour  20 \n",
      "\n",
      "Elapsed time is 13275.296811 seconds \n",
      "\n",
      "hour  21 \n",
      "\n",
      "Elapsed time is 13694.369189 seconds \n",
      "\n",
      "hour  01 \n",
      "\n",
      "Elapsed time is 13799.606569 seconds \n",
      "\n",
      "hour  02 \n",
      "\n",
      "Elapsed time is 13904.618791 seconds \n",
      "\n",
      "hour  03 \n",
      "\n",
      "Elapsed time is 14008.660940 seconds \n",
      "\n",
      "hour  04 \n",
      "\n",
      "Elapsed time is 14110.267095 seconds \n",
      "\n",
      "hour  05 \n",
      "\n",
      "Elapsed time is 14213.012381 seconds \n",
      "\n",
      "hour  06 \n",
      "\n",
      "@Elapsed time is 14312.663824 seconds \n",
      "\n",
      "hour  07 \n",
      "\n",
      "Elapsed time is 14415.053254 seconds \n",
      "\n",
      "hour  08 \n",
      "\n",
      "Elapsed time is 14519.011381 seconds \n",
      "\n",
      "hour  09 \n",
      "\n",
      "Elapsed time is 14623.944580 seconds \n",
      "\n",
      "hour  10 \n",
      "\n",
      "Elapsed time is 14728.234308 seconds \n",
      "\n",
      "hour  11 \n",
      "\n",
      "@@@Elapsed time is 14827.914412 seconds \n",
      "\n",
      "hour  12 \n",
      "\n",
      "@@@Elapsed time is 14928.487545 seconds \n",
      "\n",
      "hour  13 \n",
      "\n",
      "@@@Elapsed time is 15029.063284 seconds \n",
      "\n",
      "hour  14 \n",
      "\n",
      "@@@@@Elapsed time is 15124.611266 seconds \n",
      "\n",
      "hour  15 \n",
      "\n",
      "@@Elapsed time is 15226.489579 seconds \n",
      "\n",
      "hour  16 \n",
      "\n",
      "Elapsed time is 15331.309004 seconds \n",
      "\n",
      "hour  17 \n",
      "\n",
      "@@@@Elapsed time is 15430.887842 seconds \n",
      "\n",
      "hour  18 \n",
      "\n",
      "@Elapsed time is 15534.837399 seconds \n",
      "\n",
      "hour  19 \n",
      "\n",
      "Elapsed time is 15640.411567 seconds \n",
      "\n",
      "hour  20 \n",
      "\n",
      "Elapsed time is 15746.220810 seconds \n",
      "\n",
      "hour  21 \n",
      "\n",
      "@@@Elapsed time is 15845.765477 seconds \n",
      "\n",
      "hour  22 \n",
      "\n",
      "Elapsed time is 15949.022184 seconds \n",
      "\n",
      "hour  23 \n",
      "\n",
      "Elapsed time is 16053.294827 seconds \n",
      "\n",
      "day  2021-08-30 \n",
      "\n",
      "hour  00 \n",
      "\n",
      "Elapsed time is 16157.936561 seconds \n",
      "\n",
      "hour  01 \n",
      "\n",
      "Elapsed time is 16262.990684 seconds \n",
      "\n",
      "hour  02 \n",
      "\n",
      "Elapsed time is 16366.896104 seconds \n",
      "\n",
      "hour  03 \n",
      "\n",
      "Elapsed time is 16471.416663 seconds \n",
      "\n",
      "hour  04 \n",
      "\n",
      "@Elapsed time is 16572.509833 seconds \n",
      "\n",
      "hour  05 \n",
      "\n",
      "Elapsed time is 16676.512186 seconds \n",
      "\n",
      "hour  06 \n",
      "\n",
      "@@@Elapsed time is 16775.025712 seconds \n",
      "\n",
      "hour  07 \n",
      "\n",
      "@@@@@@Elapsed time is 16869.759214 seconds \n",
      "\n",
      "hour  08 \n",
      "\n",
      "Elapsed time is 16973.486745 seconds \n",
      "\n",
      "hour  09 \n",
      "\n",
      "Elapsed time is 17079.329693 seconds \n",
      "\n",
      "hour  10 \n",
      "\n",
      "Elapsed time is 17185.014624 seconds \n",
      "\n",
      "hour  11 \n",
      "\n",
      "@Elapsed time is 17291.170020 seconds \n",
      "\n",
      "hour  12 \n",
      "\n",
      "Elapsed time is 17398.636000 seconds \n",
      "\n",
      "hour  13 \n",
      "\n",
      "@@@Elapsed time is 17499.813639 seconds \n",
      "\n",
      "hour  14 \n",
      "\n",
      "@Elapsed time is 17602.552986 seconds \n",
      "\n",
      "hour  15 \n",
      "\n",
      "Elapsed time is 17706.921472 seconds \n",
      "\n",
      "hour  16 \n",
      "\n",
      "Elapsed time is 17810.946859 seconds \n",
      "\n",
      "hour  17 \n",
      "\n",
      "@Elapsed time is 17914.154759 seconds \n",
      "\n",
      "hour  18 \n",
      "\n",
      "Elapsed time is 18018.150841 seconds \n",
      "\n",
      "hour  19 \n",
      "\n",
      "@Elapsed time is 18121.138506 seconds \n",
      "\n",
      "hour  20 \n",
      "\n",
      "Elapsed time is 18225.759120 seconds \n",
      "\n",
      "hour  21 \n",
      "\n",
      "@@Elapsed time is 18326.688423 seconds \n",
      "\n",
      "hour  22 \n",
      "\n",
      "@@@@Elapsed time is 18423.799052 seconds \n",
      "\n",
      "hour  23 \n",
      "\n",
      "Elapsed time is 18528.625127 seconds \n",
      "\n",
      "day  2021-08-31 \n",
      "\n",
      "hour  00 \n",
      "\n",
      "Elapsed time is 18632.789071 seconds \n",
      "\n",
      "hour  01 \n",
      "\n",
      "Elapsed time is 18736.606908 seconds \n",
      "\n",
      "hour  02 \n",
      "\n",
      "Elapsed time is 18841.845030 seconds \n",
      "\n",
      "hour  03 \n",
      "\n",
      "Elapsed time is 18943.812121 seconds \n",
      "\n",
      "hour  04 \n",
      "\n",
      "Elapsed time is 19046.091211 seconds \n",
      "\n",
      "hour  05 \n",
      "\n",
      "Elapsed time is 19148.251606 seconds \n",
      "\n",
      "hour  06 \n",
      "\n",
      "Elapsed time is 19251.533882 seconds \n",
      "\n",
      "hour  07 \n",
      "\n",
      "Elapsed time is 19356.372116 seconds \n",
      "\n",
      "hour  08 \n",
      "\n",
      "Elapsed time is 19462.352469 seconds \n",
      "\n",
      "hour  09 \n",
      "\n",
      "Elapsed time is 19566.603241 seconds \n",
      "\n",
      "hour  10 \n",
      "\n",
      "Elapsed time is 19672.464323 seconds \n",
      "\n",
      "hour  11 \n",
      "\n",
      "@@Elapsed time is 19775.595525 seconds \n",
      "\n",
      "hour  12 \n",
      "\n",
      "@@@@Elapsed time is 19875.890119 seconds \n",
      "\n",
      "hour  13 \n",
      "\n",
      "@@@Elapsed time is 19977.028091 seconds \n",
      "\n",
      "hour  14 \n",
      "\n",
      "Elapsed time is 20082.856382 seconds \n",
      "\n",
      "hour  15 \n",
      "\n",
      "Elapsed time is 20187.564688 seconds \n",
      "\n",
      "hour  16 \n",
      "\n",
      "@Elapsed time is 20291.479449 seconds \n",
      "\n",
      "hour  17 \n",
      "\n",
      "Elapsed time is 20396.279338 seconds \n",
      "\n",
      "hour  18 \n",
      "\n",
      "Elapsed time is 20501.598403 seconds \n",
      "\n",
      "hour  19 \n",
      "\n",
      "@Elapsed time is 20604.363162 seconds \n",
      "\n",
      "hour  20 \n",
      "\n",
      "Elapsed time is 20709.020517 seconds \n",
      "\n",
      "hour  21 \n",
      "\n",
      "Elapsed time is 20813.704526 seconds \n",
      "\n",
      "hour  22 \n",
      "\n",
      "Elapsed time is 20918.155743 seconds \n",
      "\n",
      "hour  23 \n",
      "\n",
      "Elapsed time is 21022.056473 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_sounds(bucket_name, days_list, hours_list, label_list, start_date = datetime(xxxx,x,xx))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
